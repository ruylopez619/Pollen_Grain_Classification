{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"pgrivUCsK9bV"},"source":["# MobileViT: A mobile-friendly Transformer-based model for image classification\n","\n","**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n","**Date created:** 2021/10/20<br>\n","**Last modified:** 2021/10/20<br>\n","**Description:** MobileViT for image classification with combined benefits of convolutions and Transformers."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uU4hbh3JK9bY"},"source":["## Introduction\n","\n","In this example, we implement the MobileViT architecture\n","([Mehta et al.](https://arxiv.org/abs/2110.02178)),\n","which combines the benefits of Transformers\n","([Vaswani et al.](https://arxiv.org/abs/1706.03762))\n","and convolutions. With Transformers, we can capture long-range dependencies that result\n","in global representations. With convolutions, we can capture spatial relationships that\n","model locality.\n","\n","Besides combining the properties of Transformers and convolutions, the authors introduce\n","MobileViT as a general-purpose mobile-friendly backbone for different image recognition\n","tasks. Their findings suggest that, performance-wise, MobileViT is better than other\n","models with the same or higher complexity ([MobileNetV3](https://arxiv.org/abs/1905.02244),\n","for example), while being efficient on mobile devices."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iafR5ponK9bY"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12532,"status":"ok","timestamp":1683310356185,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"vWTllV8nI-7R","outputId":"38ab2908-e148-45ab-b9d3-f1ed017ef0d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow_addons in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.20.0)\n","Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow_addons) (22.0)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\lib\\site-packages)\n"]}],"source":["!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  1\n"]}],"source":["import tensorflow as tf\n","tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5285,"status":"ok","timestamp":1683310361458,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"MlmFzXtNK9bY","outputId":"d7743f33-703e-48a1-f792-a1589553f20b"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import tensorflow as tf\n","\n","from keras.applications import imagenet_utils\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","\n","import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":645,"status":"ok","timestamp":1683310362094,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"xBAl7M65J2kZ"},"outputs":[],"source":["from collections import Counter\n","import os\n","import cv2\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from datetime import datetime\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SubnjwYZK9bZ"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683310362095,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"mFLNenXzK9ba"},"outputs":[],"source":["# Values are from table 4.\n","patch_size = 4  # 2x2, for the Transformer blocks.\n","image_size = 128\n","expansion_factor = 2  # expansion factor for the MobileNetV2 blocks."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"32qyuZtLK9ba"},"source":["## MobileViT utilities\n","\n","The MobileViT architecture is comprised of the following blocks:\n","\n","* Strided 3x3 convolutions that process the input image.\n","* [MobileNetV2](https://arxiv.org/abs/1801.04381)-style inverted residual blocks for\n","downsampling the resolution of the intermediate feature maps.\n","* MobileViT blocks that combine the benefits of Transformers and convolutions. It is\n","presented in the figure below (taken from the\n","[original paper](https://arxiv.org/abs/2110.02178)):\n","\n","\n","![](https://i.imgur.com/mANnhI7.png)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683310362095,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"aTMRtYYbK9ba"},"outputs":[],"source":["def conv_block(x, filters=16, kernel_size=3, strides=2):\n","    conv_layer = layers.Conv2D(\n","        filters, kernel_size, strides=strides, activation=tf.nn.swish, padding=\"same\"\n","    )\n","    return conv_layer(x)\n","\n","\n","# Reference: https://git.io/JKgtC\n","\n","\n","def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n","    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n","    m = layers.BatchNormalization()(m)\n","    m = tf.nn.swish(m)\n","\n","    if strides == 2:\n","        m = layers.ZeroPadding2D(padding=imagenet_utils.correct_pad(m, 3))(m)\n","    m = layers.DepthwiseConv2D(\n","        3, strides=strides, padding=\"same\" if strides == 1 else \"valid\", use_bias=False\n","    )(m)\n","    m = layers.BatchNormalization()(m)\n","    m = tf.nn.swish(m)\n","\n","    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n","    m = layers.BatchNormalization()(m)\n","\n","    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n","        return layers.Add()([m, x])\n","    return m\n","\n","\n","# Reference:\n","# https://keras.io/examples/vision/image_classification_with_vision_transformer/\n","\n","\n","def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.swish)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x\n","\n","\n","def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, x])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n","        # Skip connection 2.\n","        x = layers.Add()([x3, x2])\n","\n","    return x\n","\n","\n","def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n","    # Local projection with convolutions.\n","    local_features = conv_block(x, filters=projection_dim, strides=strides)\n","    local_features = conv_block(\n","        local_features, filters=projection_dim, kernel_size=1, strides=strides\n","    )\n","\n","    # Unfold into patches and then pass through Transformers.\n","    num_patches = int((local_features.shape[1] * local_features.shape[2]) / patch_size)\n","    non_overlapping_patches = layers.Reshape((patch_size, num_patches, projection_dim))(\n","        local_features\n","    )\n","    global_features = transformer_block(\n","        non_overlapping_patches, num_blocks, projection_dim\n","    )\n","\n","    # Fold into conv-like feature-maps.\n","    folded_feature_map = layers.Reshape((*local_features.shape[1:-1], projection_dim))(\n","        global_features\n","    )\n","\n","    # Apply point-wise conv -> concatenate with the input features.\n","    folded_feature_map = conv_block(\n","        folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides\n","    )\n","    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map])\n","\n","    # Fuse the local and global features using a convoluion layer.\n","    local_global_features = conv_block(\n","        local_global_features, filters=projection_dim, strides=strides\n","    )\n","\n","    return local_global_features\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I9bKJvM6K9bb"},"source":["**More on the MobileViT block**:\n","\n","* First, the feature representations (A) go through convolution blocks that capture local\n","relationships. The expected shape of a single entry here would be `(h, w, num_channels)`.\n","* Then they get unfolded into another vector with shape `(p, n, num_channels)`,\n","where `p` is the area of a small patch, and `n` is `(h * w) / p`. So, we end up with `n`\n","non-overlapping patches.\n","* This unfolded vector is then passed through a Tranformer block that captures global\n","relationships between the patches.\n","* The output vector (B) is again folded into a vector of shape `(h, w, num_channels)`\n","resembling a feature map coming out of convolutions.\n","\n","Vectors A and B are then passed through two more convolutional layers to fuse the local\n","and global representations. Notice how the spatial resolution of the final vector remains\n","unchanged at this point. The authors also present an explanation of how the MobileViT\n","block resembles a convolution block of a CNN. For more details, please refer to the\n","original paper."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gW1Ik3OmK9bb"},"source":["Next, we combine these blocks together and implement the MobileViT architecture (XXS\n","variant). The following figure (taken from the original paper) presents a schematic\n","representation of the architecture:\n","\n","![](https://i.ibb.co/sRbVRBN/image.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yT2-zIsaK9bd"},"source":["## Load and prepare the dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qxtB5V2CrGa_"},"source":["## Veri yükleme"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19820,"status":"ok","timestamp":1683310436063,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"QpxaoBrCrx6u","outputId":"451f383d-a648-4840-e8f3-e051d47db0a4"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683310390919,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"3JNkLoynHeWB"},"outputs":[],"source":["# IMAGE\n","RAW_IMG_SIZE = 128\n","NUM_CLASSES = 268\n","INPUT_SHAPE = (RAW_IMG_SIZE, RAW_IMG_SIZE, 3)\n","SPLIT_SEED = 103\n","\n","# DATA\n","BUFFER_SIZE = 512\n","BATCH_SIZE = 256\n","\n","# AUGMENTATION\n","IMAGE_SIZE = RAW_IMG_SIZE\n","PATCH_SIZE = 16\n","NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n","\n","# OPTIMIZER\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 0.0001\n","\n","# TRAINING\n","EPOCHS = 50\n","\n","# ARCHITECTURE\n","LAYER_NORM_EPS = 1e-6\n","TRANSFORMER_LAYERS = 8\n","PROJECTION_DIM = 64\n","NUM_HEADS = 4\n","TRANSFORMER_UNITS = [\n","    PROJECTION_DIM * 2,\n","    PROJECTION_DIM,\n","]\n","MLP_HEAD_UNITS = [2048, 1024]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1683310695734,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"ir3uymL1IHsp"},"outputs":[],"source":["image_size = RAW_IMG_SIZE"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3102,"status":"ok","timestamp":1683310700355,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"sFGQyvTcrNaX"},"outputs":[],"source":["num_classes = 268\n","input_shape = (128, 128, 3)\n","boyut = (128, 128)\n","\n","pathh='C:\\\\Users\\\\PC\\\\OneDrive\\\\Masaüstü\\\\polen-github\\\\Veriler\\\\hepsi\\\\5\\\\128'\n","y_train_aug_le= np.loadtxt(pathh+'/y_train_aug_le.txt', dtype=float)\n","y_train_aug_cat= np.loadtxt(pathh+'/y_train_aug_cat.txt', dtype=float)\n","y_val_le= np.loadtxt(pathh+'/y_val_le.txt', dtype=float)\n","y_val_cat= np.loadtxt(pathh+'/y_val_cat.txt', dtype=float)\n","y_test_le= np.loadtxt(pathh+'/y_test_le.txt', dtype=float)\n","y_test_cat= np.loadtxt(pathh+'/y_test_cat.txt', dtype=float)\n","x_train= np.load(pathh+'/x_train.npy')\n","x_val= np.load(pathh+'/x_val.npy')\n","x_test= np.load(pathh+'/x_test.npy')\n","y_test= np.load(pathh+'/y_test.npy')\n","y_val= np.load(pathh+'/y_val.npy')\n","y_train= np.load(pathh+'/y_train.npy')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EGiVHKtqK9bd"},"source":["## Train a MobileViT (XXS) model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1849,"status":"ok","timestamp":1683310704962,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"jD-b8jo7VHc0"},"outputs":[],"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        # layers.Resizing(image_size, image_size),\n","        # layers.RandomFlip(\"horizontal_and_vertical\"),\n","        # layers.RandomRotation(factor=0.02),\n","        # layers.GaussianNoise(0.3),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","data_augmentation.layers[0].adapt(x_train)\n","# data_augmentation = keras.Sequential(\n","#     [\n","#         layers.Normalization(),\n","#         layers.Resizing(image_size, image_size),\n","#         layers.RandomFlip(\"horizontal\"),\n","#         layers.RandomRotation(factor=0.02),\n","#         layers.RandomZoom(\n","#             height_factor=0.2, width_factor=0.2\n","#         ),\n","#     ],\n","#     name=\"data_augmentation\",\n","# )\n","# \n","\n","# class RandomBrightness: A preprocessing layer which randomly adjusts brightness during training.\n","# class RandomContrast: A preprocessing layer which randomly adjusts contrast during training.\n","# class RandomCrop: A preprocessing layer which randomly crops images during training.\n","# class RandomFlip: A preprocessing layer which randomly flips images during training.\n","# class RandomHeight: A preprocessing layer which randomly varies image height during training.\n","# class RandomRotation: A preprocessing layer which randomly rotates images during training.\n","# class RandomTranslation: A preprocessing layer which randomly translates images during training.\n","# class RandomWidth: A preprocessing layer which randomly varies image width during training.\n","# class RandomZoom: A preprocessing layer which randomly zooms images during training."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5552,"status":"ok","timestamp":1683310712444,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"D3vb8XngK9bc","outputId":"59d2455b-0b4d-4e85-8903-a93ca797165c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," data_augmentation (Sequential)  (None, 128, 128, 3)  7          ['input_1[0][0]']                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 64, 64, 16)   448         ['data_augmentation[0][0]']      \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 64, 64, 32)   512         ['conv2d[0][0]']                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['conv2d_1[0][0]']               \n"," alization)                                                                                       \n","                                                                                                  \n"," tf.nn.silu (TFOpLambda)        (None, 64, 64, 32)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 64, 64, 32)  288         ['tf.nn.silu[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 64, 64, 32)  128         ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_1 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 64, 64, 16)   512         ['tf.nn.silu_1[0][0]']           \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 64, 64, 16)  64          ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 64, 64, 16)   0           ['batch_normalization_2[0][0]',  \n","                                                                  'conv2d[0][0]']                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 64, 64, 32)   512         ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_2 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," zero_padding2d (ZeroPadding2D)  (None, 65, 65, 32)  0           ['tf.nn.silu_2[0][0]']           \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 32)  288         ['zero_padding2d[0][0]']         \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 32, 32, 32)  128         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_3 (TFOpLambda)      (None, 32, 32, 32)   0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 32, 32, 24)   768         ['tf.nn.silu_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 32, 32, 48)   1152        ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 32, 32, 48)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_4 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 48)  432         ['tf.nn.silu_4[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 32, 32, 48)  192         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_5 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 32, 32, 24)   1152        ['tf.nn.silu_5[0][0]']           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_8[0][0]',  \n","                                                                  'batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 32, 32, 48)   1152        ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 32, 32, 48)  192         ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.nn.silu_6 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 32, 32, 48)  432         ['tf.nn.silu_6[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 32, 32, 48)  192         ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_7 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 32, 32, 24)   1152        ['tf.nn.silu_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 32, 32, 24)  96          ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_2 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_11[0][0]', \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 32, 32, 48)   1152        ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 32, 32, 48)  192         ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_8 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," zero_padding2d_1 (ZeroPadding2  (None, 33, 33, 48)  0           ['tf.nn.silu_8[0][0]']           \n"," D)                                                                                               \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 48)  432         ['zero_padding2d_1[0][0]']       \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 16, 16, 48)  192         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_9 (TFOpLambda)      (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 16, 16, 48)   2304        ['tf.nn.silu_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 16, 16, 48)  192         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 16, 16, 64)   27712       ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 16, 16, 64)   4160        ['conv2d_11[0][0]']              \n","                                                                                                  \n"," reshape (Reshape)              (None, 4, 64, 64)    0           ['conv2d_12[0][0]']              \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 4, 64, 64)   128         ['reshape[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 4, 64, 64)   33216       ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," add_3 (Add)                    (None, 4, 64, 64)    0           ['multi_head_attention[0][0]',   \n","                                                                  'reshape[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 4, 64, 64)   128         ['add_3[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 4, 64, 128)   8320        ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout (Dropout)              (None, 4, 64, 128)   0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 4, 64, 64)    8256        ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 4, 64, 64)    0           ['dense_1[0][0]']                \n","                                                                                                  \n"," add_4 (Add)                    (None, 4, 64, 64)    0           ['dropout_1[0][0]',              \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 4, 64, 64)   128         ['add_4[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 4, 64, 64)   33216       ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," add_5 (Add)                    (None, 4, 64, 64)    0           ['multi_head_attention_1[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 4, 64, 64)   128         ['add_5[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_2 (Dense)                (None, 4, 64, 128)   8320        ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 4, 64, 128)   0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 4, 64, 64)    8256        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 4, 64, 64)    0           ['dense_3[0][0]']                \n","                                                                                                  \n"," add_6 (Add)                    (None, 4, 64, 64)    0           ['dropout_3[0][0]',              \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, 16, 16, 64)   0           ['add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 16, 16, 48)   3120        ['reshape_1[0][0]']              \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 16, 16, 96)   0           ['batch_normalization_14[0][0]', \n","                                                                  'conv2d_13[0][0]']              \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 16, 16, 64)   55360       ['concatenate[0][0]']            \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 16, 16, 128)  8192        ['conv2d_14[0][0]']              \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 16, 16, 128)  512        ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_10 (TFOpLambda)     (None, 16, 16, 128)  0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," zero_padding2d_2 (ZeroPadding2  (None, 17, 17, 128)  0          ['tf.nn.silu_10[0][0]']          \n"," D)                                                                                               \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 8, 8, 128)   1152        ['zero_padding2d_2[0][0]']       \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 8, 8, 128)   512         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_11 (TFOpLambda)     (None, 8, 8, 128)    0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 8, 8, 64)     8192        ['tf.nn.silu_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 8, 8, 80)     46160       ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 8, 8, 80)     6480        ['conv2d_17[0][0]']              \n","                                                                                                  \n"," reshape_2 (Reshape)            (None, 4, 16, 80)    0           ['conv2d_18[0][0]']              \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 4, 16, 80)   160         ['reshape_2[0][0]']              \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," add_7 (Add)                    (None, 4, 16, 80)    0           ['multi_head_attention_2[0][0]', \n","                                                                  'reshape_2[0][0]']              \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 4, 16, 80)   160         ['add_7[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_4 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 4, 16, 160)   0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, 4, 16, 80)    12880       ['dropout_4[0][0]']              \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 4, 16, 80)    0           ['dense_5[0][0]']                \n","                                                                                                  \n"," add_8 (Add)                    (None, 4, 16, 80)    0           ['dropout_5[0][0]',              \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 4, 16, 80)   160         ['add_8[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," add_9 (Add)                    (None, 4, 16, 80)    0           ['multi_head_attention_3[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 4, 16, 80)   160         ['add_9[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 4, 16, 160)   0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 4, 16, 80)    12880       ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 4, 16, 80)    0           ['dense_7[0][0]']                \n","                                                                                                  \n"," add_10 (Add)                   (None, 4, 16, 80)    0           ['dropout_7[0][0]',              \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," layer_normalization_8 (LayerNo  (None, 4, 16, 80)   160         ['add_10[0][0]']                 \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_4 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_8[0][0]',  \n"," eadAttention)                                                    'layer_normalization_8[0][0]']  \n","                                                                                                  \n"," add_11 (Add)                   (None, 4, 16, 80)    0           ['multi_head_attention_4[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," layer_normalization_9 (LayerNo  (None, 4, 16, 80)   160         ['add_11[0][0]']                 \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_8 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_9[0][0]']  \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 4, 16, 160)   0           ['dense_8[0][0]']                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 4, 16, 80)    12880       ['dropout_8[0][0]']              \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 4, 16, 80)    0           ['dense_9[0][0]']                \n","                                                                                                  \n"," add_12 (Add)                   (None, 4, 16, 80)    0           ['dropout_9[0][0]',              \n","                                                                  'add_11[0][0]']                 \n","                                                                                                  \n"," layer_normalization_10 (LayerN  (None, 4, 16, 80)   160         ['add_12[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_5 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_10[0][0]', \n"," eadAttention)                                                    'layer_normalization_10[0][0]'] \n","                                                                                                  \n"," add_13 (Add)                   (None, 4, 16, 80)    0           ['multi_head_attention_5[0][0]', \n","                                                                  'add_12[0][0]']                 \n","                                                                                                  \n"," layer_normalization_11 (LayerN  (None, 4, 16, 80)   160         ['add_13[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_10 (Dense)               (None, 4, 16, 160)   12960       ['layer_normalization_11[0][0]'] \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 4, 16, 160)   0           ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_11 (Dense)               (None, 4, 16, 80)    12880       ['dropout_10[0][0]']             \n","                                                                                                  \n"," dropout_11 (Dropout)           (None, 4, 16, 80)    0           ['dense_11[0][0]']               \n","                                                                                                  \n"," add_14 (Add)                   (None, 4, 16, 80)    0           ['dropout_11[0][0]',             \n","                                                                  'add_13[0][0]']                 \n","                                                                                                  \n"," reshape_3 (Reshape)            (None, 8, 8, 80)     0           ['add_14[0][0]']                 \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 8, 8, 64)     5184        ['reshape_3[0][0]']              \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 8, 8, 128)    0           ['batch_normalization_17[0][0]', \n","                                                                  'conv2d_19[0][0]']              \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 8, 8, 80)     92240       ['concatenate_1[0][0]']          \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 8, 8, 160)    12800       ['conv2d_20[0][0]']              \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 8, 8, 160)   640         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_12 (TFOpLambda)     (None, 8, 8, 160)    0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," zero_padding2d_3 (ZeroPadding2  (None, 9, 9, 160)   0           ['tf.nn.silu_12[0][0]']          \n"," D)                                                                                               \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 4, 4, 160)   1440        ['zero_padding2d_3[0][0]']       \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 4, 4, 160)   640         ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.nn.silu_13 (TFOpLambda)     (None, 4, 4, 160)    0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 4, 4, 80)     12800       ['tf.nn.silu_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 4, 4, 80)    320         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 4, 4, 96)     69216       ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 4, 4, 96)     9312        ['conv2d_23[0][0]']              \n","                                                                                                  \n"," reshape_4 (Reshape)            (None, 4, 4, 96)     0           ['conv2d_24[0][0]']              \n","                                                                                                  \n"," layer_normalization_12 (LayerN  (None, 4, 4, 96)    192         ['reshape_4[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_6 (MultiH  (None, 4, 4, 96)    74400       ['layer_normalization_12[0][0]', \n"," eadAttention)                                                    'layer_normalization_12[0][0]'] \n","                                                                                                  \n"," add_15 (Add)                   (None, 4, 4, 96)     0           ['multi_head_attention_6[0][0]', \n","                                                                  'reshape_4[0][0]']              \n","                                                                                                  \n"," layer_normalization_13 (LayerN  (None, 4, 4, 96)    192         ['add_15[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_12 (Dense)               (None, 4, 4, 192)    18624       ['layer_normalization_13[0][0]'] \n","                                                                                                  \n"," dropout_12 (Dropout)           (None, 4, 4, 192)    0           ['dense_12[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, 4, 4, 96)     18528       ['dropout_12[0][0]']             \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 4, 4, 96)     0           ['dense_13[0][0]']               \n","                                                                                                  \n"," add_16 (Add)                   (None, 4, 4, 96)     0           ['dropout_13[0][0]',             \n","                                                                  'add_15[0][0]']                 \n","                                                                                                  \n"," layer_normalization_14 (LayerN  (None, 4, 4, 96)    192         ['add_16[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_7 (MultiH  (None, 4, 4, 96)    74400       ['layer_normalization_14[0][0]', \n"," eadAttention)                                                    'layer_normalization_14[0][0]'] \n","                                                                                                  \n"," add_17 (Add)                   (None, 4, 4, 96)     0           ['multi_head_attention_7[0][0]', \n","                                                                  'add_16[0][0]']                 \n","                                                                                                  \n"," layer_normalization_15 (LayerN  (None, 4, 4, 96)    192         ['add_17[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_14 (Dense)               (None, 4, 4, 192)    18624       ['layer_normalization_15[0][0]'] \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 4, 4, 192)    0           ['dense_14[0][0]']               \n","                                                                                                  \n"," dense_15 (Dense)               (None, 4, 4, 96)     18528       ['dropout_14[0][0]']             \n","                                                                                                  \n"," dropout_15 (Dropout)           (None, 4, 4, 96)     0           ['dense_15[0][0]']               \n","                                                                                                  \n"," add_18 (Add)                   (None, 4, 4, 96)     0           ['dropout_15[0][0]',             \n","                                                                  'add_17[0][0]']                 \n","                                                                                                  \n"," layer_normalization_16 (LayerN  (None, 4, 4, 96)    192         ['add_18[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_8 (MultiH  (None, 4, 4, 96)    74400       ['layer_normalization_16[0][0]', \n"," eadAttention)                                                    'layer_normalization_16[0][0]'] \n","                                                                                                  \n"," add_19 (Add)                   (None, 4, 4, 96)     0           ['multi_head_attention_8[0][0]', \n","                                                                  'add_18[0][0]']                 \n","                                                                                                  \n"," layer_normalization_17 (LayerN  (None, 4, 4, 96)    192         ['add_19[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_16 (Dense)               (None, 4, 4, 192)    18624       ['layer_normalization_17[0][0]'] \n","                                                                                                  \n"," dropout_16 (Dropout)           (None, 4, 4, 192)    0           ['dense_16[0][0]']               \n","                                                                                                  \n"," dense_17 (Dense)               (None, 4, 4, 96)     18528       ['dropout_16[0][0]']             \n","                                                                                                  \n"," dropout_17 (Dropout)           (None, 4, 4, 96)     0           ['dense_17[0][0]']               \n","                                                                                                  \n"," add_20 (Add)                   (None, 4, 4, 96)     0           ['dropout_17[0][0]',             \n","                                                                  'add_19[0][0]']                 \n","                                                                                                  \n"," reshape_5 (Reshape)            (None, 4, 4, 96)     0           ['add_20[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 4, 4, 80)     7760        ['reshape_5[0][0]']              \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 4, 4, 160)    0           ['batch_normalization_20[0][0]', \n","                                                                  'conv2d_25[0][0]']              \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 4, 4, 96)     138336      ['concatenate_2[0][0]']          \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 4, 4, 320)    31040       ['conv2d_26[0][0]']              \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 320)         0           ['conv2d_27[0][0]']              \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," dense_18 (Dense)               (None, 5)            1605        ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,307,628\n","Trainable params: 1,305,077\n","Non-trainable params: 2,551\n","__________________________________________________________________________________________________\n"]}],"source":["\n","def create_mobilevit(num_classes=5):\n","    inputs = keras.Input((image_size, image_size, 3))\n","  # Degisiklik\n","  # ORJ    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n","    x = data_augmentation(inputs)\n","\n","    # Initial conv-stem -> MV2 block.\n","    x = conv_block(x, filters=16)\n","    x = inverted_residual_block(\n","        x, expanded_channels=16 * expansion_factor, output_channels=16\n","    )\n","\n","    # Downsampling with MV2 block.\n","    x = inverted_residual_block(\n","        x, expanded_channels=16 * expansion_factor, output_channels=24, strides=2\n","    )\n","    x = inverted_residual_block(\n","        x, expanded_channels=24 * expansion_factor, output_channels=24\n","    )\n","    x = inverted_residual_block(\n","        x, expanded_channels=24 * expansion_factor, output_channels=24\n","    )\n","\n","    # First MV2 -> MobileViT block.\n","    x = inverted_residual_block(\n","        x, expanded_channels=24 * expansion_factor, output_channels=48, strides=2\n","    )\n","    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n","\n","    # Second MV2 -> MobileViT block.\n","    x = inverted_residual_block(\n","        x, expanded_channels=64 * expansion_factor, output_channels=64, strides=2\n","    )\n","    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n","\n","    # Third MV2 -> MobileViT block.\n","    x = inverted_residual_block(\n","        x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n","    )\n","    x = mobilevit_block(x, num_blocks=3, projection_dim=96)\n","    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n","\n","    # Classification head.\n","    x = layers.GlobalAvgPool2D()(x)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","    return keras.Model(inputs, outputs)\n","\n","\n","mobilevit_xxs = create_mobilevit()\n","mobilevit_xxs.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2933064,"status":"ok","timestamp":1683313648213,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"irB5SWC8K9be","outputId":"3027b832-cb2c-4ad9-da00-842cb179254b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","137/137 [==============================] - 24s 106ms/step - loss: 4.1760 - accuracy: 0.1324 - top_k_categorical_accuracy: 0.3700 - cohen_kappa: 0.1181 - val_loss: 5.7804 - val_accuracy: 0.0199 - val_top_k_categorical_accuracy: 0.0541 - val_cohen_kappa: -1.1921e-07 - lr: 0.0010\n","Epoch 2/100\n","137/137 [==============================] - 13s 96ms/step - loss: 3.0138 - accuracy: 0.3407 - top_k_categorical_accuracy: 0.6946 - cohen_kappa: 0.3326 - val_loss: 6.3532 - val_accuracy: 0.0114 - val_top_k_categorical_accuracy: 0.0285 - val_cohen_kappa: 0.0037 - lr: 0.0010\n","Epoch 3/100\n","137/137 [==============================] - 13s 97ms/step - loss: 2.4134 - accuracy: 0.5192 - top_k_categorical_accuracy: 0.8514 - cohen_kappa: 0.5137 - val_loss: 7.0773 - val_accuracy: 0.0114 - val_top_k_categorical_accuracy: 0.0285 - val_cohen_kappa: 0.0045 - lr: 0.0010\n","Epoch 4/100\n","137/137 [==============================] - 14s 106ms/step - loss: 1.9517 - accuracy: 0.6715 - top_k_categorical_accuracy: 0.9341 - cohen_kappa: 0.6680 - val_loss: 4.7721 - val_accuracy: 0.1453 - val_top_k_categorical_accuracy: 0.3761 - val_cohen_kappa: 0.1403 - lr: 0.0010\n","Epoch 5/100\n","137/137 [==============================] - 15s 111ms/step - loss: 1.6769 - accuracy: 0.7693 - top_k_categorical_accuracy: 0.9673 - cohen_kappa: 0.7668 - val_loss: 2.2884 - val_accuracy: 0.5726 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.5704 - lr: 0.0010\n","Epoch 6/100\n","137/137 [==============================] - 15s 109ms/step - loss: 1.4724 - accuracy: 0.8440 - top_k_categorical_accuracy: 0.9857 - cohen_kappa: 0.8424 - val_loss: 2.4938 - val_accuracy: 0.5641 - val_top_k_categorical_accuracy: 0.8262 - val_cohen_kappa: 0.5618 - lr: 0.0010\n","Epoch 7/100\n","137/137 [==============================] - 15s 110ms/step - loss: 1.3572 - accuracy: 0.8834 - top_k_categorical_accuracy: 0.9925 - cohen_kappa: 0.8821 - val_loss: 2.5230 - val_accuracy: 0.5527 - val_top_k_categorical_accuracy: 0.8376 - val_cohen_kappa: 0.5503 - lr: 0.0010\n","Epoch 8/100\n","137/137 [==============================] - 16s 115ms/step - loss: 1.2611 - accuracy: 0.9141 - top_k_categorical_accuracy: 0.9974 - cohen_kappa: 0.9132 - val_loss: 2.6086 - val_accuracy: 0.5356 - val_top_k_categorical_accuracy: 0.8091 - val_cohen_kappa: 0.5331 - lr: 0.0010\n","Epoch 9/100\n","137/137 [==============================] - 15s 113ms/step - loss: 1.1850 - accuracy: 0.9422 - top_k_categorical_accuracy: 0.9984 - cohen_kappa: 0.9416 - val_loss: 2.6016 - val_accuracy: 0.5157 - val_top_k_categorical_accuracy: 0.8262 - val_cohen_kappa: 0.5131 - lr: 0.0010\n","Epoch 10/100\n","137/137 [==============================] - 15s 111ms/step - loss: 1.1286 - accuracy: 0.9600 - top_k_categorical_accuracy: 0.9993 - cohen_kappa: 0.9595 - val_loss: 2.2774 - val_accuracy: 0.6040 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.6019 - lr: 0.0010\n","Epoch 11/100\n","137/137 [==============================] - 15s 109ms/step - loss: 1.0912 - accuracy: 0.9697 - top_k_categorical_accuracy: 0.9998 - cohen_kappa: 0.9694 - val_loss: 2.3723 - val_accuracy: 0.5983 - val_top_k_categorical_accuracy: 0.8348 - val_cohen_kappa: 0.5961 - lr: 0.0010\n","Epoch 12/100\n","137/137 [==============================] - 15s 110ms/step - loss: 1.0653 - accuracy: 0.9770 - top_k_categorical_accuracy: 0.9998 - cohen_kappa: 0.9767 - val_loss: 2.3011 - val_accuracy: 0.6268 - val_top_k_categorical_accuracy: 0.8490 - val_cohen_kappa: 0.6248 - lr: 0.0010\n","Epoch 13/100\n","137/137 [==============================] - 15s 109ms/step - loss: 1.0515 - accuracy: 0.9806 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9803 - val_loss: 2.5927 - val_accuracy: 0.5499 - val_top_k_categorical_accuracy: 0.8177 - val_cohen_kappa: 0.5474 - lr: 0.0010\n","Epoch 14/100\n","137/137 [==============================] - 15s 109ms/step - loss: 1.0290 - accuracy: 0.9866 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9865 - val_loss: 2.3656 - val_accuracy: 0.6154 - val_top_k_categorical_accuracy: 0.8519 - val_cohen_kappa: 0.6133 - lr: 0.0010\n","Epoch 15/100\n","137/137 [==============================] - 14s 103ms/step - loss: 1.0139 - accuracy: 0.9889 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9888 - val_loss: 2.3865 - val_accuracy: 0.6097 - val_top_k_categorical_accuracy: 0.8433 - val_cohen_kappa: 0.6076 - lr: 0.0010\n","Epoch 16/100\n","137/137 [==============================] - 15s 110ms/step - loss: 1.0047 - accuracy: 0.9900 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9899 - val_loss: 2.3814 - val_accuracy: 0.5897 - val_top_k_categorical_accuracy: 0.8519 - val_cohen_kappa: 0.5874 - lr: 0.0010\n","Epoch 17/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9900 - accuracy: 0.9928 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9927 - val_loss: 2.3403 - val_accuracy: 0.6268 - val_top_k_categorical_accuracy: 0.8376 - val_cohen_kappa: 0.6247 - lr: 0.0010\n","Epoch 18/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9931 - accuracy: 0.9927 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9926 - val_loss: 2.4294 - val_accuracy: 0.5926 - val_top_k_categorical_accuracy: 0.8348 - val_cohen_kappa: 0.5904 - lr: 0.0010\n","Epoch 19/100\n","137/137 [==============================] - 15s 110ms/step - loss: 1.0047 - accuracy: 0.9886 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9885 - val_loss: 2.4776 - val_accuracy: 0.5926 - val_top_k_categorical_accuracy: 0.8348 - val_cohen_kappa: 0.5903 - lr: 0.0010\n","Epoch 20/100\n","137/137 [==============================] - 15s 113ms/step - loss: 1.0066 - accuracy: 0.9879 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9877 - val_loss: 2.4858 - val_accuracy: 0.5726 - val_top_k_categorical_accuracy: 0.8234 - val_cohen_kappa: 0.5704 - lr: 0.0010\n","Epoch 21/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9949 - accuracy: 0.9906 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9905 - val_loss: 2.4389 - val_accuracy: 0.5897 - val_top_k_categorical_accuracy: 0.8319 - val_cohen_kappa: 0.5875 - lr: 0.0010\n","Epoch 22/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9724 - accuracy: 0.9946 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9946 - val_loss: 2.3403 - val_accuracy: 0.6068 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.6047 - lr: 0.0010\n","Epoch 23/100\n","137/137 [==============================] - 14s 101ms/step - loss: 0.9873 - accuracy: 0.9914 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9914 - val_loss: 2.3563 - val_accuracy: 0.6154 - val_top_k_categorical_accuracy: 0.8376 - val_cohen_kappa: 0.6133 - lr: 0.0010\n","Epoch 24/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9955 - accuracy: 0.9884 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9882 - val_loss: 2.3594 - val_accuracy: 0.6068 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.6047 - lr: 0.0010\n","Epoch 25/100\n","137/137 [==============================] - 13s 98ms/step - loss: 1.0055 - accuracy: 0.9867 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9866 - val_loss: 2.2716 - val_accuracy: 0.6325 - val_top_k_categorical_accuracy: 0.8547 - val_cohen_kappa: 0.6304 - lr: 0.0010\n","Epoch 26/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9869 - accuracy: 0.9909 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9908 - val_loss: 2.4158 - val_accuracy: 0.6040 - val_top_k_categorical_accuracy: 0.8234 - val_cohen_kappa: 0.6019 - lr: 0.0010\n","Epoch 27/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9852 - accuracy: 0.9908 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9907 - val_loss: 2.3524 - val_accuracy: 0.6154 - val_top_k_categorical_accuracy: 0.8234 - val_cohen_kappa: 0.6132 - lr: 0.0010\n","Epoch 28/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9617 - accuracy: 0.9942 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9942 - val_loss: 2.2521 - val_accuracy: 0.6524 - val_top_k_categorical_accuracy: 0.8661 - val_cohen_kappa: 0.6505 - lr: 0.0010\n","Epoch 29/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9541 - accuracy: 0.9961 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9961 - val_loss: 2.2280 - val_accuracy: 0.6610 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.6591 - lr: 0.0010\n","Epoch 30/100\n","137/137 [==============================] - 13s 95ms/step - loss: 0.9532 - accuracy: 0.9956 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9956 - val_loss: 2.5205 - val_accuracy: 0.5897 - val_top_k_categorical_accuracy: 0.8291 - val_cohen_kappa: 0.5876 - lr: 0.0010\n","Epoch 31/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9549 - accuracy: 0.9960 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9959 - val_loss: 2.3229 - val_accuracy: 0.6353 - val_top_k_categorical_accuracy: 0.8433 - val_cohen_kappa: 0.6333 - lr: 0.0010\n","Epoch 32/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9662 - accuracy: 0.9927 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9926 - val_loss: 2.2757 - val_accuracy: 0.6439 - val_top_k_categorical_accuracy: 0.8689 - val_cohen_kappa: 0.6420 - lr: 0.0010\n","Epoch 33/100\n","137/137 [==============================] - 13s 95ms/step - loss: 0.9921 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9871 - val_loss: 2.5079 - val_accuracy: 0.5812 - val_top_k_categorical_accuracy: 0.8262 - val_cohen_kappa: 0.5789 - lr: 0.0010\n","Epoch 34/100\n","137/137 [==============================] - 13s 95ms/step - loss: 1.0203 - accuracy: 0.9823 - top_k_categorical_accuracy: 0.9998 - cohen_kappa: 0.9821 - val_loss: 2.4764 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8405 - val_cohen_kappa: 0.5818 - lr: 0.0010\n","Epoch 35/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9870 - accuracy: 0.9892 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9891 - val_loss: 2.5360 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8291 - val_cohen_kappa: 0.5819 - lr: 0.0010\n","Epoch 36/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9665 - accuracy: 0.9931 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9930 - val_loss: 2.2371 - val_accuracy: 0.6467 - val_top_k_categorical_accuracy: 0.8746 - val_cohen_kappa: 0.6447 - lr: 0.0010\n","Epoch 37/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9411 - accuracy: 0.9975 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9975 - val_loss: 2.3155 - val_accuracy: 0.6211 - val_top_k_categorical_accuracy: 0.8575 - val_cohen_kappa: 0.6191 - lr: 0.0010\n","Epoch 38/100\n","137/137 [==============================] - 13s 95ms/step - loss: 0.9224 - accuracy: 0.9997 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9997 - val_loss: 2.1908 - val_accuracy: 0.6752 - val_top_k_categorical_accuracy: 0.8661 - val_cohen_kappa: 0.6735 - lr: 0.0010\n","Epoch 39/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9136 - accuracy: 0.9999 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9999 - val_loss: 2.1896 - val_accuracy: 0.6724 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.6706 - lr: 0.0010\n","Epoch 40/100\n","137/137 [==============================] - 13s 95ms/step - loss: 0.9084 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1635 - val_accuracy: 0.6895 - val_top_k_categorical_accuracy: 0.8689 - val_cohen_kappa: 0.6878 - lr: 0.0010\n","Epoch 41/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9078 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.6838 - val_top_k_categorical_accuracy: 0.8803 - val_cohen_kappa: 0.6821 - lr: 0.0010\n","Epoch 42/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9062 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.2037 - val_accuracy: 0.6809 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.6792 - lr: 0.0010\n","Epoch 43/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9053 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1861 - val_accuracy: 0.6895 - val_top_k_categorical_accuracy: 0.8689 - val_cohen_kappa: 0.6878 - lr: 0.0010\n","Epoch 44/100\n","137/137 [==============================] - 13s 94ms/step - loss: 0.9130 - accuracy: 0.9995 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9995 - val_loss: 2.2474 - val_accuracy: 0.6524 - val_top_k_categorical_accuracy: 0.8519 - val_cohen_kappa: 0.6505 - lr: 0.0010\n","Epoch 45/100\n","137/137 [==============================] - 13s 96ms/step - loss: 1.0290 - accuracy: 0.9733 - top_k_categorical_accuracy: 0.9993 - cohen_kappa: 0.9730 - val_loss: 3.6222 - val_accuracy: 0.3704 - val_top_k_categorical_accuracy: 0.6410 - val_cohen_kappa: 0.3670 - lr: 0.0010\n","Epoch 46/100\n","137/137 [==============================] - 13s 95ms/step - loss: 1.2093 - accuracy: 0.9203 - top_k_categorical_accuracy: 0.9954 - cohen_kappa: 0.9195 - val_loss: 3.0404 - val_accuracy: 0.4530 - val_top_k_categorical_accuracy: 0.7094 - val_cohen_kappa: 0.4500 - lr: 0.0010\n","Epoch 47/100\n","137/137 [==============================] - 13s 96ms/step - loss: 0.9983 - accuracy: 0.9863 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9862 - val_loss: 2.2936 - val_accuracy: 0.6182 - val_top_k_categorical_accuracy: 0.8575 - val_cohen_kappa: 0.6163 - lr: 0.0010\n","Epoch 48/100\n","137/137 [==============================] - 13s 97ms/step - loss: 0.9466 - accuracy: 0.9967 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9967 - val_loss: 2.2116 - val_accuracy: 0.6809 - val_top_k_categorical_accuracy: 0.8632 - val_cohen_kappa: 0.6792 - lr: 0.0010\n","Epoch 49/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9310 - accuracy: 0.9983 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9983 - val_loss: 2.2010 - val_accuracy: 0.6952 - val_top_k_categorical_accuracy: 0.8718 - val_cohen_kappa: 0.6935 - lr: 0.0010\n","Epoch 50/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9220 - accuracy: 0.9987 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9987 - val_loss: 2.2467 - val_accuracy: 0.6382 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.6362 - lr: 0.0010\n","Epoch 51/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9290 - accuracy: 0.9973 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9972 - val_loss: 2.2069 - val_accuracy: 0.6581 - val_top_k_categorical_accuracy: 0.8718 - val_cohen_kappa: 0.6563 - lr: 0.0010\n","Epoch 52/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9210 - accuracy: 0.9989 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9989 - val_loss: 2.1630 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8775 - val_cohen_kappa: 0.6906 - lr: 0.0010\n","Epoch 53/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9190 - accuracy: 0.9992 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9992 - val_loss: 2.1879 - val_accuracy: 0.6695 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6677 - lr: 0.0010\n","Epoch 54/100\n","137/137 [==============================] - 15s 107ms/step - loss: 0.9345 - accuracy: 0.9967 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9967 - val_loss: 2.3112 - val_accuracy: 0.6410 - val_top_k_categorical_accuracy: 0.8547 - val_cohen_kappa: 0.6391 - lr: 0.0010\n","Epoch 55/100\n","137/137 [==============================] - 15s 107ms/step - loss: 0.9437 - accuracy: 0.9946 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9946 - val_loss: 2.5624 - val_accuracy: 0.5698 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.5675 - lr: 0.0010\n","Epoch 56/100\n","137/137 [==============================] - 15s 108ms/step - loss: 0.9852 - accuracy: 0.9860 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9859 - val_loss: 2.4064 - val_accuracy: 0.5869 - val_top_k_categorical_accuracy: 0.8376 - val_cohen_kappa: 0.5847 - lr: 0.0010\n","Epoch 57/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9715 - accuracy: 0.9917 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9916 - val_loss: 2.3859 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.5819 - lr: 0.0010\n","Epoch 58/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9400 - accuracy: 0.9966 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9966 - val_loss: 2.2879 - val_accuracy: 0.6296 - val_top_k_categorical_accuracy: 0.8689 - val_cohen_kappa: 0.6276 - lr: 0.0010\n","Epoch 59/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9264 - accuracy: 0.9981 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9980 - val_loss: 2.1197 - val_accuracy: 0.6581 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.6563 - lr: 0.0010\n","Epoch 60/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9309 - accuracy: 0.9967 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9967 - val_loss: 2.3835 - val_accuracy: 0.6239 - val_top_k_categorical_accuracy: 0.8604 - val_cohen_kappa: 0.6219 - lr: 0.0010\n","Epoch 61/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9360 - accuracy: 0.9959 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9959 - val_loss: 2.2683 - val_accuracy: 0.6724 - val_top_k_categorical_accuracy: 0.8490 - val_cohen_kappa: 0.6706 - lr: 0.0010\n","Epoch 62/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9424 - accuracy: 0.9956 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9955 - val_loss: 2.2682 - val_accuracy: 0.6410 - val_top_k_categorical_accuracy: 0.8746 - val_cohen_kappa: 0.6391 - lr: 0.0010\n","Epoch 63/100\n","137/137 [==============================] - 14s 105ms/step - loss: 0.9293 - accuracy: 0.9973 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9972 - val_loss: 2.3519 - val_accuracy: 0.6182 - val_top_k_categorical_accuracy: 0.8519 - val_cohen_kappa: 0.6162 - lr: 0.0010\n","Epoch 64/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.9325 - accuracy: 0.9964 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9964 - val_loss: 2.2287 - val_accuracy: 0.6895 - val_top_k_categorical_accuracy: 0.8632 - val_cohen_kappa: 0.6878 - lr: 0.0010\n","Epoch 65/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9564 - accuracy: 0.9912 - top_k_categorical_accuracy: 0.9998 - cohen_kappa: 0.9911 - val_loss: 2.5117 - val_accuracy: 0.5783 - val_top_k_categorical_accuracy: 0.8291 - val_cohen_kappa: 0.5761 - lr: 0.0010\n","Epoch 66/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9687 - accuracy: 0.9901 - top_k_categorical_accuracy: 0.9999 - cohen_kappa: 0.9900 - val_loss: 2.4254 - val_accuracy: 0.6154 - val_top_k_categorical_accuracy: 0.8462 - val_cohen_kappa: 0.6133 - lr: 0.0010\n","Epoch 67/100\n","137/137 [==============================] - 15s 107ms/step - loss: 0.9390 - accuracy: 0.9964 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9964 - val_loss: 2.2427 - val_accuracy: 0.6667 - val_top_k_categorical_accuracy: 0.8661 - val_cohen_kappa: 0.6649 - lr: 0.0010\n","Epoch 68/100\n","137/137 [==============================] - 15s 110ms/step - loss: 0.9230 - accuracy: 0.9984 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9984 - val_loss: 2.1809 - val_accuracy: 0.6809 - val_top_k_categorical_accuracy: 0.8803 - val_cohen_kappa: 0.6792 - lr: 0.0010\n","Epoch 69/100\n","137/137 [==============================] - 14s 100ms/step - loss: 0.9090 - accuracy: 0.9995 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9995 - val_loss: 2.1670 - val_accuracy: 0.6866 - val_top_k_categorical_accuracy: 0.8832 - val_cohen_kappa: 0.6849 - lr: 0.0010\n","Epoch 70/100\n","137/137 [==============================] - 14s 100ms/step - loss: 0.9019 - accuracy: 0.9999 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 0.9999 - val_loss: 2.1507 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6907 - lr: 1.0000e-04\n","Epoch 71/100\n","137/137 [==============================] - 15s 111ms/step - loss: 0.8993 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1386 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 72/100\n","137/137 [==============================] - 15s 111ms/step - loss: 0.8981 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1397 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8974 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 73/100\n","137/137 [==============================] - 15s 106ms/step - loss: 0.8974 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1345 - val_accuracy: 0.6980 - val_top_k_categorical_accuracy: 0.8974 - val_cohen_kappa: 0.6964 - lr: 1.0000e-04\n","Epoch 74/100\n","137/137 [==============================] - 15s 106ms/step - loss: 0.8969 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.6952 - val_top_k_categorical_accuracy: 0.8946 - val_cohen_kappa: 0.6935 - lr: 1.0000e-04\n","Epoch 75/100\n","137/137 [==============================] - 15s 111ms/step - loss: 0.8964 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1437 - val_accuracy: 0.7066 - val_top_k_categorical_accuracy: 0.8946 - val_cohen_kappa: 0.7050 - lr: 1.0000e-04\n","Epoch 76/100\n","137/137 [==============================] - 15s 108ms/step - loss: 0.8963 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1362 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 77/100\n","137/137 [==============================] - 15s 107ms/step - loss: 0.8958 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1506 - val_accuracy: 0.6980 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6964 - lr: 1.0000e-04\n","Epoch 78/100\n","137/137 [==============================] - 15s 109ms/step - loss: 0.8958 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1409 - val_accuracy: 0.6952 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6935 - lr: 1.0000e-04\n","Epoch 79/100\n","137/137 [==============================] - 15s 112ms/step - loss: 0.8954 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8946 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 80/100\n","137/137 [==============================] - 16s 116ms/step - loss: 0.8951 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.6980 - val_top_k_categorical_accuracy: 0.8974 - val_cohen_kappa: 0.6964 - lr: 1.0000e-04\n","Epoch 81/100\n","137/137 [==============================] - 14s 102ms/step - loss: 0.8950 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1398 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 82/100\n","137/137 [==============================] - 14s 102ms/step - loss: 0.8945 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8974 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 83/100\n","137/137 [==============================] - 14s 99ms/step - loss: 0.8946 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1531 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8974 - val_cohen_kappa: 0.6907 - lr: 1.0000e-04\n","Epoch 84/100\n","137/137 [==============================] - 17s 126ms/step - loss: 0.8942 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1420 - val_accuracy: 0.6980 - val_top_k_categorical_accuracy: 0.8946 - val_cohen_kappa: 0.6964 - lr: 1.0000e-04\n","Epoch 85/100\n","137/137 [==============================] - 22s 164ms/step - loss: 0.8939 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1504 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 86/100\n","137/137 [==============================] - 20s 145ms/step - loss: 0.8936 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1459 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 87/100\n","137/137 [==============================] - 21s 152ms/step - loss: 0.8933 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1632 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.6906 - lr: 1.0000e-04\n","Epoch 88/100\n","137/137 [==============================] - 18s 129ms/step - loss: 0.8933 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1549 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 89/100\n","137/137 [==============================] - 16s 117ms/step - loss: 0.8932 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1583 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6906 - lr: 1.0000e-04\n","Epoch 90/100\n","137/137 [==============================] - 16s 113ms/step - loss: 0.8930 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1632 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 91/100\n","137/137 [==============================] - 16s 120ms/step - loss: 0.8926 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1590 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 92/100\n","137/137 [==============================] - 18s 133ms/step - loss: 0.8927 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.7037 - val_top_k_categorical_accuracy: 0.8917 - val_cohen_kappa: 0.7021 - lr: 1.0000e-04\n","Epoch 93/100\n","137/137 [==============================] - 21s 155ms/step - loss: 0.8926 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8860 - val_cohen_kappa: 0.6992 - lr: 1.0000e-04\n","Epoch 94/100\n","137/137 [==============================] - 20s 143ms/step - loss: 0.8926 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1604 - val_accuracy: 0.6952 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.6935 - lr: 1.0000e-04\n","Epoch 95/100\n","137/137 [==============================] - 20s 145ms/step - loss: 0.8925 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1769 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8860 - val_cohen_kappa: 0.6906 - lr: 1.0000e-04\n","Epoch 96/100\n","137/137 [==============================] - 20s 150ms/step - loss: 0.8919 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1644 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.6906 - lr: 1.0000e-05\n","Epoch 97/100\n","137/137 [==============================] - 18s 130ms/step - loss: 0.8918 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1649 - val_accuracy: 0.7009 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.6992 - lr: 1.0000e-05\n","Epoch 98/100\n","137/137 [==============================] - 20s 143ms/step - loss: 0.8917 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1640 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8860 - val_cohen_kappa: 0.6906 - lr: 1.0000e-05\n","Epoch 99/100\n","137/137 [==============================] - 18s 135ms/step - loss: 0.8917 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1619 - val_accuracy: 0.6980 - val_top_k_categorical_accuracy: 0.8889 - val_cohen_kappa: 0.6964 - lr: 1.0000e-05\n","Epoch 100/100\n","137/137 [==============================] - 21s 150ms/step - loss: 0.8915 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - cohen_kappa: 1.0000 - val_loss: 2.1650 - val_accuracy: 0.6952 - val_top_k_categorical_accuracy: 0.8860 - val_cohen_kappa: 0.6935 - lr: 1.0000e-05\n"]}],"source":["learning_rate = 0.001\n","label_smoothing_factor = 0.1\n","epochs = 100\n","\n","optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing_factor)\n","\n","\n","def run_experiment(epochs=epochs):\n","    mobilevit_xxs = create_mobilevit(num_classes=num_classes)\n","    mobilevit_xxs.compile(\n","        optimizer= optimizer,\n","        loss= loss_fn, \n","        metrics=['accuracy', 'top_k_categorical_accuracy', tfa.metrics.CohenKappa(num_classes=268, sparse_labels=False),] \n","    )\n","\n","    kayit_adresi = \"C:\\\\Users\\\\PC\\OneDrive\\\\Masaüstü\\\\polen-github\\\\grad_modeller\\\\mobilevit-20230521T093724Z-001\\\\mobilevit\\\\model_kayitlari\"\n","    if not os.path.exists(kayit_adresi):\n","        os.mkdir(kayit_adresi)\n","        \n","    zaman = datetime.today().strftime('%d-%m-%Y-%H-%M')\n","    model_kayit_noktasi_adresi = os.path.join(kayit_adresi,zaman)\n","    os.mkdir(model_kayit_noktasi_adresi)\n","\n","    # kayit adresleri\n","    checkpoint_filepath  = os.path.join(model_kayit_noktasi_adresi,\"model2.hdf5\")\n","\n","    # CHECKPOINT\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_filepath,\n","    save_weights_only = True,\n","    monitor='val_accuracy',\n","    save_best_only = True)\n","\n","    # LRR\n","    lrr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',  \n","    factor=.1,  # Factor by which learning rate will be reduced\n","    patience=20,\n","    min_lr=1e-5)\n","\n","    callbacks = [lrr, checkpoint_callback]\n","\n","    history = mobilevit_xxs.fit(\n","        x=x_train,\n","        y=y_train_aug_cat,\n","        epochs=epochs,\n","        batch_size=128,\n","        validation_data=(x_val,y_val_cat),\n","        callbacks=callbacks\n","    )\n","\n","\n","    return mobilevit_xxs, model_kayit_noktasi_adresi\n","\n","\n","mobilevit_xxs, model_kayit_noktasi_adresi = run_experiment()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","#Load the predicted labels and true labels\n","y_pred = mobilevit_xxs.predict(x_test)  # Load your predicted labels\n","y_true = y_test  # Load your true labels\n","\n","#Create the confusion matrix\n","cm = confusion_matrix(y_true, y_pred.argmax(axis=-1))\n","\n","tp = np.diag(cm)\n","fp = np.sum(cm, axis=0) - tp\n","fn = np.sum(cm, axis=1) - tp\n","\n","precision = tp / (tp + fp)\n","recall = tp / (tp + fn)\n","f1 = 2 * (precision * recall) / (precision + recall)\n","\n","arr_replaced = np.nan_to_num(f1, nan=0)\n","#Print the F1 score\n","print(\"F1 Score:\", np.mean(arr_replaced))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3779,"status":"ok","timestamp":1683313651982,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"k7xU06L8UCtC","outputId":"7eb28782-9f50-425e-b6cd-1f36383bb669"},"outputs":[],"source":["loss, accuracy, top_5_accuracy, kappa_score = mobilevit_xxs.evaluate(x_test, y_test_cat)\n","print(f\"Test loss: {round(loss, 2)}\")\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","print(f\"Kappa Score:{kappa_score}\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["txt_kayit_adresi    = os.path.join(model_kayit_noktasi_adresi, f\"agumentasyon_modeli.txt\")\n","try:\n","    with open(txt_kayit_adresi, \"w\") as fh:\n","        fh.write(f\"Epok sayisi: {EPOCHS}\\nbasarisi: Test accuracy: {round(accuracy * 100, 2)}%\\nCohenKappa Skoru: {kappa_score}\\nF1 Skor: {np.mean(arr_replaced)}\\nResim Boyutu: {image_size}\\nPatch Boyutu: {patch_size}\\nTest top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\\n loss='categorical_crossentropy' metrics=['accuracy']\\n\")\n","        data_augmentation.summary(print_fn=lambda x: fh.write(x + '\\n'))\n","\n","except Exception as e2:\n","    print(\"Model txt ye yazdirilamadi, hata: \", e2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683313651983,"user":{"displayName":"Emir Meşe","userId":"17575555061670766305"},"user_tz":-180},"id":"s659xubKUEVa","outputId":"b3ceddc5-1f5b-454a-813f-f1ac921281df"},"outputs":[],"source":["grafik_adresi = os.path.join(model_kayit_noktasi_adresi, \"Grafik.png\")\n","\n","try:\n","        \n","    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12))\n","    ax1.plot(mobilevit_xxs.history['loss'], color='b', label=\"Training loss\")\n","    ax1.plot(mobilevit_xxs.history['val_loss'], color='r', label=\"validation loss\")\n","    ax1.set_xticks(np.arange(0, epochs, 10))\n","    ax1.legend(loc='upper left')\n","\n","    ax2.plot(mobilevit_xxs.history['accuracy'], color='b', label=\"Training accuracy\")\n","    ax2.plot(mobilevit_xxs.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n","    ax2.set_xticks(np.arange(0, epochs, 10))\n","    ax2.legend(loc='upper left')\n","\n","    ax3.plot(mobilevit_xxs.history['top-5-accuracy'], color='b',label=\"train-top-5-accuracy-accuracy\")\n","    ax3.plot(mobilevit_xxs.history['val_top-5-accuracy'], color='r',label=\"val_top-5-accuracy\")\n","    ax3.set_xticks(np.arange(0, epochs, 10))\n","    ax3.legend(loc='upper left')\n","    plt.savefig(grafik_adresi, bbox_inches='tight', facecolor='w')\n","    plt.show()\n","\n","except Exception as e:\n","    print(f\"Grafik çizilemedi {e}\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["P_SIsgJ96_bn"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
